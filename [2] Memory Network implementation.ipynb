{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Implementation-of-memory-networks\" data-toc-modified-id=\"Implementation-of-memory-networks-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Implementation of memory networks</a></div><div class=\"lev2 toc-item\"><a href=\"#I-Module\" data-toc-modified-id=\"I-Module-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>I Module</a></div><div class=\"lev1 toc-item\"><a href=\"#Margin-Ranking-Loss\" data-toc-modified-id=\"Margin-Ranking-Loss-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Margin Ranking Loss</a></div><div class=\"lev1 toc-item\"><a href=\"#Building-the-Memory-Network\" data-toc-modified-id=\"Building-the-Memory-Network-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Building the Memory Network</a></div><div class=\"lev2 toc-item\"><a href=\"#Parametrization\" data-toc-modified-id=\"Parametrization-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Parametrization</a></div><div class=\"lev2 toc-item\"><a href=\"#Network-implementation\" data-toc-modified-id=\"Network-implementation-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Network implementation</a></div><div class=\"lev2 toc-item\"><a href=\"#Testing-the-Memory-Network-Inference\" data-toc-modified-id=\"Testing-the-Memory-Network-Inference-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Testing the Memory Network Inference</a></div><div class=\"lev1 toc-item\"><a href=\"#Memory-module\" data-toc-modified-id=\"Memory-module-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Memory module</a></div><div class=\"lev2 toc-item\"><a href=\"#Memory-module-testing\" data-toc-modified-id=\"Memory-module-testing-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Memory module testing</a></div><div class=\"lev1 toc-item\"><a href=\"#Inference-module\" data-toc-modified-id=\"Inference-module-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Inference module</a></div><div class=\"lev2 toc-item\"><a href=\"#Inference-module-testing\" data-toc-modified-id=\"Inference-module-testing-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Inference module testing</a></div><div class=\"lev2 toc-item\"><a href=\"#Testing-the-implementation\" data-toc-modified-id=\"Testing-the-implementation-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Testing the implementation</a></div><div class=\"lev1 toc-item\"><a href=\"#Testing-the-Memory-Network\" data-toc-modified-id=\"Testing-the-Memory-Network-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Testing the Memory Network</a></div><div class=\"lev1 toc-item\"><a href=\"#Scrap\" data-toc-modified-id=\"Scrap-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Scrap</a></div><div class=\"lev2 toc-item\"><a href=\"#Copying-a-clone-to-put-it-in-a-memory\" data-toc-modified-id=\"Copying-a-clone-to-put-it-in-a-memory-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Copying a clone to put it in a memory</a></div><div class=\"lev2 toc-item\"><a href=\"#Multiplying-tensors\" data-toc-modified-id=\"Multiplying-tensors-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Multiplying tensors</a></div><div class=\"lev1 toc-item\"><a href=\"#Scrap\" data-toc-modified-id=\"Scrap-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Scrap</a></div><div class=\"lev1 toc-item\"><a href=\"#Scrap-on-nnGraph-operations\" data-toc-modified-id=\"Scrap-on-nnGraph-operations-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Scrap on nnGraph operations</a></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T15:40:04",
     "start_time": "2017-08-28T13:40:04.649Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'nngraph';\n",
    "require 'utils.OneHot'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of memory networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory network is a sequence of 4 modules that allowing better assignement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**input feature map** â€“ converts the incoming input to the internal feature representation\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "We decided to use two representations for our model : OneHot Vectorization and word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T15:27:09",
     "start_time": "2017-08-28T13:27:09.478Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "oui\t\n"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug.getregistry()['IModule'] = nil\n",
    "IModule,parent  = torch.class('IModule','nn.Module')\n",
    "\n",
    "function IModule:__init(param)\n",
    "    parent.__init(self) \n",
    "    print(param)\n",
    "end\n",
    "\n",
    "a = IModule.new('oui')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T15:41:55",
     "start_time": "2017-08-28T13:41:55.829Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"MemoryNetworkOneHot = {}...\"]:3: <name> or '...' expected near ')'",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"MemoryNetworkOneHot = {}...\"]:3: <name> or '...' expected near ')'"
     ]
    }
   ],
   "source": [
    "MemoryNetworkOneHot = {}\n",
    "\n",
    "function MemoryNetworkOneHot.create(vocab_size, mem_size)\n",
    "    local inputs = {}\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    ------------------ I Module -------------------\n",
    "    x =  OneHot.new(vocab_size)(inputs[1])\n",
    "    ------------------ G Module -------------------    \n",
    "    \n",
    "    ------------------ O Module -------------------    \n",
    "    \n",
    "    ------------------ R Module -------------------\n",
    "     \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MemoryNetwork.create"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Margin Ranking Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Memory Networks training is based on Stochastic Gradient Descent and [Margin Ranking](https://github.com/torch/nn/blob/master/doc/criterion.md#nn.MarginRankingCriterion) Loss that is already implemented in torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Memory Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T15:39:45",
     "start_time": "2017-08-28T13:39:45.612Z"
    }
   },
   "source": [
    "## Parametrization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T16:31:07",
     "start_time": "2017-08-28T14:31:07.232Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SEQ_LENGTH = 5\n",
    "VOCAB_SIZE = 30\n",
    "MEM_SIZE = 3\n",
    "NUM_MEM = 2\n",
    "FEATURE_SIZE = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:08:30",
     "start_time": "2017-08-29T12:08:30.630Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function create_network(SEQ_LENGTH)\n",
    "    ------------------ Initialization -------------------\n",
    "    SEQ_LENGTH = SEQ_LENGTH or 5\n",
    "    local inputs = {}\n",
    "    local outputs = {}\n",
    "    table.insert(inputs,nn.Identity()()) --:annotate{name='Identity'}\n",
    "    ------------------ I Module -------------------\n",
    "    local mlp = nn.Sequential()\n",
    "    mlp:add()\n",
    "    local net = nn.Parallel(1,2)(inputs[1])\n",
    "    for i=1,SEQ_LENGTH do\n",
    "        local one_t = OneHot(VOCAB_SIZE)(net)\n",
    "    end\n",
    "    ------------------ G Module -------------------    \n",
    "    -- m = MemoryModule.new(NUM_MEM,MEM_SIZE,VOCAB_SIZE)\n",
    "    local g_mod = MemoryModule.new(NUM_MEM,MEM_SIZE,VOCAB_SIZE)()\n",
    "    ------------------ O Module -------------------    \n",
    "    local o_mod = InferenceModule.new(30,3*30)({i_mod,g_mod})\n",
    "    ------------------ R Module -------------------\n",
    "    table.insert(outputs,o_mod)\n",
    "    return nn.gModule(inputs,outputs)\n",
    "end \n",
    "\n",
    "--a = torch.Tensor(1,5):fill(2)\n",
    "--    r = mlp:forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:08:30",
     "start_time": "2017-08-29T12:08:30.876Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nngraph.Node\n",
       "{\n",
       "  data : \n",
       "    {\n",
       "      module : \n",
       "        nn.Identity\n",
       "        {\n",
       "          gradInput : DoubleTensor - empty\n",
       "          _type : torch.DoubleTensor\n",
       "          output : DoubleTensor - empty\n",
       "        }\n",
       "      reverseMap : table: 0x0707bb98\n",
       "      mapindex : table: 0x0707bb08\n",
       "      annotations : \n",
       "        {\n",
       "          _debugLabel : [[string \"function create_network(SEQ_LENGTH)...\"]]:6_\n",
       "        }\n",
       "    }\n",
       "  visited : false\n",
       "  id : 0\n",
       "  marked : false\n",
       "  children : table: 0x07121570\n",
       "}\n",
       "{\n",
       "  1 : DoubleTensor - size: 3x30\n",
       "  2 : DoubleTensor - size: 3x30\n",
       "}\n"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "/Users/david/torch/install/share/lua/5.1/nngraph/init.lua:48: inputs[1] is nil (typo / bad index?)\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/david/torch/install/share/lua/5.1/nngraph/init.lua:48: in function </Users/david/torch/install/share/lua/5.1/nngraph/init.lua:25>\n\t[C]: at 0x0654ae90\n\t[string \"function create_network(SEQ_LENGTH)...\"]:17: in function 'create_network'\n\t[string \"local mlp = create_network()...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:210: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01061f8a10",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "/Users/david/torch/install/share/lua/5.1/nngraph/init.lua:48: inputs[1] is nil (typo / bad index?)\nstack traceback:\n\t[C]: in function 'error'\n\t/Users/david/torch/install/share/lua/5.1/nngraph/init.lua:48: in function </Users/david/torch/install/share/lua/5.1/nngraph/init.lua:25>\n\t[C]: at 0x0654ae90\n\t[string \"function create_network(SEQ_LENGTH)...\"]:17: in function 'create_network'\n\t[string \"local mlp = create_network()...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:210: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x01061f8a10"
     ]
    }
   ],
   "source": [
    "local mlp = create_network()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the Memory Network Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "aa = mlp:forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T10:56:21",
     "start_time": "2017-08-29T08:56:21.705Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T16:49:19",
     "start_time": "2017-08-28T14:49:19.584Z"
    }
   },
   "source": [
    "# Memory module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T10:50:05",
     "start_time": "2017-08-29T08:50:05.110Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MemoryModule, parent = torch.class('MemoryModule','nn.Module')\n",
    "\n",
    "function MemoryModule:__init(NUM_MEM,MEM_SIZE,VOCAB_SIZE)\n",
    "    parent.__init(self)\n",
    "    self.num_mem = NUM_MEM\n",
    "    self.mem_size = MEM_SIZE\n",
    "    self.memory = {}\n",
    "    for i=1,NUM_MEM do table.insert(self.memory,torch.Tensor(MEM_SIZE,VOCAB_SIZE):fill(0)) end\n",
    "end\n",
    "\n",
    "function MemoryModule:updateOutput(input)\n",
    "    -- Replace the index memory with the input it as received\n",
    "    assert(input:size(2) == self.memory[1]:size(2), \"input size and memory size are differents\")\n",
    "    local input = input:clone()\n",
    "    local loaded_mem = 0\n",
    "    for i=1,#self.memory do\n",
    "       for j=1,self.mem_size do\n",
    "            if j + loaded_mem > input:size(1) then\n",
    "                break\n",
    "            end\n",
    "            self.memory[i][{j}] = input[{j + loaded_mem,{}}]\n",
    "        end\n",
    "        loaded_mem = loaded_mem + self.mem_size\n",
    "    end\n",
    "    return self.memory\n",
    "end\n",
    "\n",
    "function MemoryModule:getIndex(index)\n",
    "    return self.memory[index]\n",
    "end\n",
    "\n",
    "function MemoryModule:getMemorySize()\n",
    "    return #self.memory\n",
    "end\n",
    "\n",
    "function MemoryModule:getMemory()\n",
    "    return nn.JoinTable(1):forward(mem)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory module testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T10:50:06",
     "start_time": "2017-08-29T08:50:06.822Z"
    },
    "collapsed": false,
    "run_control": {
     "marked": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x30\n",
       "  2 : DoubleTensor - size: 3x30\n",
       "}\n"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = MemoryModule.new(NUM_MEM,MEM_SIZE,VOCAB_SIZE)\n",
    "mem = m:forward(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T10:53:10",
     "start_time": "2017-08-29T08:53:10.296Z"
    }
   },
   "source": [
    "# Inference module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:07:20",
     "start_time": "2017-08-29T12:07:20.568Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "InferenceModule, parent = torch.class('InferenceModule','nn.Module')\n",
    "\n",
    "function InferenceModule:__init(voc_size, feature_dim)\n",
    "    parent.__init(self)\n",
    "    local inputs = {}\n",
    "    local outputs = {}\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    -----  \n",
    "    local lin1 = nn.Linear(voc_size,feature_dim)(inputs[1])\n",
    "    local lin2 = nn.Linear(feature_dim,voc_size)(inputs[2])\n",
    "    table.insert(outputs,lin1)\n",
    "    table.insert(outputs,lin2)\n",
    "    self.mlp = nn.gModule(inputs, outputs) \n",
    "end\n",
    "\n",
    "function InferenceModule:updateOutput(input)\n",
    "    local input1 = input[1]:clone()\n",
    "    local input2 = input[2]:clone()\n",
    "    input2 = input2:transpose(1,2)\n",
    "    return self.mlp:forward{input1,input2}\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T11:30:33",
     "start_time": "2017-08-29T09:30:33.843Z"
    }
   },
   "source": [
    "## Inference module testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:07:16",
     "start_time": "2017-08-29T12:07:16.113Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "infer = InferenceModule.new(30,3*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:07:16",
     "start_time": "2017-08-29T12:07:16.355Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = torch.Tensor(3,30)\n",
    "ii = torch.Tensor(90,30)\n",
    "iii = {i,ii}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:07:17",
     "start_time": "2017-08-29T12:07:17.008Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x90\n",
       "  2 : DoubleTensor - size: 30x30\n",
       "}\n"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(infer:forward(iii))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T13:48:57",
     "start_time": "2017-08-29T11:48:57.388Z"
    }
   },
   "source": [
    "## Testing the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Memory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T11:31:36",
     "start_time": "2017-08-29T09:31:36.763Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(1,5)\n",
    "for i=1,a:size(2) do\n",
    "    a[1][i] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T11:31:38",
     "start_time": "2017-08-29T09:31:38.852Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  1 : DoubleTensor - size: 3x30\n",
       "  2 : DoubleTensor - size: 3x30\n",
       "}\n"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp:forward(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T11:30:38",
     "start_time": "2017-08-29T09:30:38.521Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T17:09:24",
     "start_time": "2017-08-28T15:09:24.968Z"
    }
   },
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copying a clone to put it in a memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T17:28:10",
     "start_time": "2017-08-28T15:28:10.359Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "valeur de a \n",
       "\t\n",
       "  2.0000e+00   2.0000e+00  2.2727e-322   0.0000e+00\n",
       "  0.0000e+00  6.2043e+223  6.2104e+175  1.3662e+161\n",
       " 7.6284e+228  1.0626e+248  3.3552e-110  1.6934e-152\n",
       " 7.6284e+228  1.0626e+248  3.3553e-110  7.3587e+223\n",
       " 3.2167e+257  5.9526e+135  1.7530e+243  4.0719e+223\n",
       " 1.4243e+261  2.6099e+180  4.1005e+223  7.3587e+223\n",
       " 4.0719e+223   7.1415e-13  6.8498e+180  4.1114e+223\n",
       " 1.7258e+243  4.0719e+223  1.3662e+161  7.1345e+159\n",
       " 2.2476e+142  2.0289e-110  3.7768e+180   2.9070e-14\n",
       " 6.0143e+175  7.3587e+223  3.2167e+257  5.9526e+135\n",
       "[torch.DoubleTensor of size 10x4]\n",
       "\n",
       "valeur de mem \n",
       "\t\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.DoubleTensor of size 16x4]\n",
       "\n",
       "valeur de a \n",
       "\t\n",
       "  2.0000e+00   2.0000e+00  2.2727e-322   0.0000e+00\n",
       "  0.0000e+00  6.2043e+223  6.2104e+175  1.3662e+161\n",
       " 7.6284e+228  1.0626e+248  3.3552e-110  1.6934e-152\n",
       " 7.6284e+228  1.0626e+248  3.3553e-110  7.3587e+223\n",
       " 3.2167e+257  5.9526e+135  1.7530e+243  4.0719e+223\n",
       " 1.4243e+261  2.6099e+180  4.1005e+223  7.3587e+223\n",
       " 4.0719e+223   7.1415e-13  6.8498e+180  4.1114e+223\n",
       " 1.7258e+243  4.0719e+223  1.3662e+161  7.1345e+159\n",
       " 2.2476e+142  2.0289e-110  3.7768e+180   2.9070e-14\n",
       " 6.0143e+175  7.3587e+223  3.2167e+257  5.9526e+135\n",
       "[torch.DoubleTensor of size 10x4]\n",
       "\n",
       "valeur de mem \n",
       "\t\n",
       "  2.0000e+00   2.0000e+00  2.2727e-322   0.0000e+00\n",
       "  0.0000e+00  6.2043e+223  6.2104e+175  1.3662e+161\n",
       " 7.6284e+228  1.0626e+248  3.3552e-110  1.6934e-152\n",
       " 7.6284e+228  1.0626e+248  3.3553e-110  7.3587e+223\n",
       " 3.2167e+257  5.9526e+135  1.7530e+243  4.0719e+223\n",
       " 1.4243e+261  2.6099e+180  4.1005e+223  7.3587e+223\n",
       " 4.0719e+223   7.1415e-13  6.8498e+180  4.1114e+223\n",
       " 1.7258e+243  4.0719e+223  1.3662e+161  7.1345e+159\n",
       " 2.2476e+142  2.0289e-110  3.7768e+180   2.9070e-14\n",
       " 6.0143e+175  7.3587e+223  3.2167e+257  5.9526e+135\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "  0.0000e+00   0.0000e+00   0.0000e+00   0.0000e+00\n",
       "[torch.DoubleTensor of size 16x4]\n",
       "\n"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local a = torch.Tensor(10,4)\n",
    "local mem = torch.Tensor(16,4)\n",
    "\n",
    "print('valeur de a \\n')\n",
    "print(a)\n",
    "print('valeur de mem \\n')\n",
    "print(mem)\n",
    "\n",
    "for i=1,a:size(1) do\n",
    "    --print(i)\n",
    "    local cl = a[{i,{}}]:clone()\n",
    "    mem[{i}] = cl\n",
    "end\n",
    "\n",
    "print('valeur de a \\n')\n",
    "print(a)\n",
    "print('valeur de mem \\n')\n",
    "print(mem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T17:27:27",
     "start_time": "2017-08-28T15:27:27.052Z"
    }
   },
   "source": [
    "## Multiplying tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T12:10:39",
     "start_time": "2017-08-29T10:10:39.996Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = torch.Tensor(10,2)\n",
    "aa = torch.Tensor(2,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T16:07:25",
     "start_time": "2017-08-28T14:07:25.663Z"
    }
   },
   "source": [
    "# Scrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-28T16:37:54",
     "start_time": "2017-08-28T14:37:54.225Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 26\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 27 to 30\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       " 0  0  0  0\n",
       "[torch.DoubleTensor of size 5x30]\n",
       "\n",
       " 0\n",
       " 1\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       " 0\n",
       "[torch.DoubleTensor of size 30]\n",
       "\n"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(r)\n",
    "print(r:select(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap on nnGraph operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-29T14:10:47",
     "start_time": "2017-08-29T12:10:47.829Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "local inputs = {}\n",
    "local outputs = {}\n",
    "\n",
    "local a = nn.Identity()()\n",
    "table.insert(inputs,nn.Identity()())\n",
    "local aa = nn.ParallelTable()(inputs[1])\n",
    "local aaa = OneHot()(aaPa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
