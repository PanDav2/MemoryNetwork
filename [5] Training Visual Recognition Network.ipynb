{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Loading-required-modules\" data-toc-modified-id=\"Loading-required-modules-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Loading required modules</a></div><div class=\"lev1 toc-item\"><a href=\"#Memory-Network\" data-toc-modified-id=\"Memory-Network-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Memory Network</a></div><div class=\"lev2 toc-item\"><a href=\"#Debugging\" data-toc-modified-id=\"Debugging-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Debugging</a></div><div class=\"lev2 toc-item\"><a href=\"#Implementation-of-the-Loss-Function\" data-toc-modified-id=\"Implementation-of-the-Loss-Function-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Implementation of the Loss Function</a></div><div class=\"lev1 toc-item\"><a href=\"#Training-the-model\" data-toc-modified-id=\"Training-the-model-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Training the model</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:33:32",
     "start_time": "2017-09-18T10:33:32.264Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'nngraph';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:33:32",
     "start_time": "2017-09-18T10:33:32.488Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saving /Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "saving its index in /Users/david/Documents/MemoryNetwork/output_lua/vocab.t7_index\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "putting sample tensor into /Users/david/Documents/MemoryNetwork/output_lua/sample.t7...\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "saving /Users/david/Documents/MemoryNetwork/output_lua/sample.t7\t\n",
       "putting label tensor into /Users/david/Documents/MemoryNetwork/output_lua/data.t7...\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "saving /Users/david/Documents/MemoryNetwork/output_lua/data.t7\t\n"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = require 'utils.data_loader';\n",
    "QUICKLOAD = false\n",
    "\n",
    "if QUICKLOAD then\n",
    "    x = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/sample.t7\")\n",
    "    y = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/label.t7\")\n",
    "    voc = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\")\n",
    "    index = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7_index\")\n",
    "else \n",
    "    input_file = \"/Users/david/Documents/MemoryNetwork/preprocessing/output.txt\"\n",
    "    out_vocab_file = \"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\"\n",
    "    out_tensor_file = \"/Users/david/Documents/MemoryNetwork/output_lua/data.t7\"\n",
    "    voc = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\")\n",
    "    index = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7_index\")\n",
    "    x, y,f = data_loader.text_to_tensor(input_file,out_vocab_file,out_tensor_file)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:33:33",
     "start_time": "2017-09-18T10:33:33.147Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 70\n",
       " 58\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 70\n",
       " 58\n",
       "[torch.LongStorage of size 2]\n",
       "\n",
       " 70\n",
       "  9\n",
       "[torch.LongStorage of size 2]\n",
       "\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-- Checking x\n",
    "print(x:size())\n",
    "-- Checking y\n",
    "print(y:size())\n",
    "-- Checking f\n",
    "print(f:size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:33:33",
     "start_time": "2017-09-18T10:33:33.509Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "-- pre-requists\n",
    "\n",
    "require 'nn';\n",
    "require 'nngraph';\n",
    "require 'models.inference_module'\n",
    "require 'utils.OneHot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T11:47:48",
     "start_time": "2017-09-18T09:47:48.595Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:33:34",
     "start_time": "2017-09-18T10:33:34.988Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'math';\n",
    "require 'nn';\n",
    "require 'nngraph';\n",
    "\n",
    "MemoryModule = {}\n",
    "\n",
    "function MemoryModule.create_network(num_mem,longuest_sentence_size,debug) -- longest_sentence,voc_size,num_mem)\n",
    "    local inputs = {}\n",
    "    local outputs = {}\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    -- \n",
    "    local reshaped_input =  nn.Reshape(1,-1)(inputs[1])\n",
    "    local mem_proj = nn.SplitTable(1)(reshaped_input):annotate{name=\"mem_proj\"}\n",
    "    -- Creating memory mapping :\n",
    "    local mem_size =  math.floor(longuest_sentence_size/num_mem)\n",
    "    if debug then print(\"num_mem = \"..num_mem) print(\"mem_size = \"..mem_size) end\n",
    "    for i=1,num_mem do\n",
    "        local mem_mapping = nn.NarrowTable(1+(i-1)*mem_size,mem_size)(mem_proj)\n",
    "        table.insert(outputs, nn.JoinTable(1)(mem_mapping)) -- Joining to get a table of tensors\n",
    "    end \n",
    "    return nn.gModule(inputs, outputs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RepresentationModule = {}\n",
    "\n",
    "function RepresentationModule.create_network(vocab_size) \n",
    "    local inputs = {}\n",
    "    local outputs = {}\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    -- \n",
    "    local one_hot = OneHot.new(vocab_size)(inputs[1]) -- One Hot Encoding sub\n",
    "    table.insert(outputs, one_hot)\n",
    "    return nn.gModule(inputs, outputs)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MixingGraph = {}\n",
    "\n",
    "function MixingGraph.create_network()\n",
    "    local inputs = {}\n",
    "    local outputs = {}\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    table.insert(inputs, nn.Identity()())\n",
    "    local repr_x = nn.Reshape(1,-1,false)(nn.Sum(1)(inputs[1]))\n",
    "    local repr_y = nn.Reshape(1,-1,false)(nn.Sum(1)(inputs[2]))\n",
    "    local sum = nn.CAddTable(1)({repr_x,repr_y})\n",
    "    table.insert(outputs, sum)\n",
    "    return nn.gModule(inputs,outputs)\n",
    "end\n",
    "\n",
    "local ee = torch.DoubleTensor(1,10):fill(1)\n",
    "local rr = torch.DoubleTensor(1,10):fill(4)\n",
    "-- print(nn.CAddTable(2):forward{ee,rr})\n",
    "\n",
    "local m = MixingGraph.create_network()\n",
    "print(m:forward{ee,rr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T14:54:20",
     "start_time": "2017-09-18T12:54:20.706Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 16\n",
       " 106    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
       "\n",
       "Columns 17 to 32\n",
       "   0    0    0    0    2    0    0    0    0    0    0    0    0    0    0    2\n",
       "\n",
       "Columns 33 to 48\n",
       "   0    0    0    0    0    2    0    0    0    2    0    0    0    0    0    0\n",
       "\n",
       "Columns 49 to 58\n",
       "   2    0    0    0    0    0    0    0    0    0\n",
       "[torch.DoubleTensor of size 1x58]\n",
       "\n"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local m = MixingGraph.create_network()\n",
    "\n",
    "local rep = RepresentationModule.create_network(VOCAB_SIZE)\n",
    "local xrepr = rep:forward(x[1])\n",
    "local yrepr = rep:forward(y[1])\n",
    "\n",
    "--print(nn.Reshape(1,-1,false):forward(nn.Sum(1):forward(yrepr)))\n",
    "print(m:forward{xrepr,yrepr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NUM_MEM = 10\n",
    "VOCAB_SIZE = 58\n",
    "N_ITERATIONS = 1000\n",
    "LEARNING_RATE = 1e-5\n",
    "\n",
    "--------------  Network Creation\n",
    "\n",
    "-- Incoding input\n",
    "local rep = RepresentationModule.create_network(VOCAB_SIZE)\n",
    "-- print(rep:forward(x[1]):size())\n",
    "-- Setting memory\n",
    "mem_mod = MemoryModule.create_network(NUM_MEM,VOCAB_SIZE)\n",
    "-- Infering on memory \n",
    "o_mod = InferenceGraph.create_network(VOCAB_SIZE,3*VOCAB_SIZE)\n",
    "-- Inferinf on Response\n",
    "r_mod = InferenceGraph.create_network(VOCAB_SIZE,3*VOCAB_SIZE)\n",
    "\n",
    "criterion = nn.MarginRankingCriterion(0.1)\n",
    "\n",
    "--------------  Support Function\n",
    "\n",
    "function print_memory_table(x_ind,fact,num_mem)\n",
    "    local sup_memory = {}\n",
    "    local temp1 = -1\n",
    "    for i=1,f[1]:size(1) do\n",
    "        local temp = math.floor(fact[x_ind][i]/num_mem)\n",
    "        if temp ~= temp1 and temp ~= 0 then \n",
    "            table.insert(sup_memory,temp)\n",
    "            temp1 = temp\n",
    "        end\n",
    "    end\n",
    "    return sup_memory\n",
    "end\n",
    "\n",
    "function get_facts_memory(x_ind,fact,num_mem)\n",
    "    local sup_memory = {}\n",
    "    local temp1 = -1\n",
    "    for i=1,f[1]:size(1) do\n",
    "        local temp = math.floor(fact[x_ind][i]/num_mem)\n",
    "        if temp ~= temp1 and temp ~= 0 then \n",
    "            table.insert(sup_memory,temp)\n",
    "            temp1 = temp\n",
    "        end\n",
    "    end\n",
    "    return sup_memory\n",
    "end\n",
    "\n",
    "function gradUpdate(mlp, x, memory, criterion, learningRate)\n",
    "   local pred = mlp:forward(x)\n",
    "   local err = criterion:forward(pred, memory)\n",
    "   local gradCriterion = criterion:backward(pred, memory)\n",
    "   mlp:zeroGradParameters()\n",
    "   mlp:backward(x, gradCriterion)\n",
    "   mlp:updateParameters(learningRate)\n",
    "end\n",
    "\n",
    "-------------- \n",
    "\n",
    "\n",
    "\n",
    "for i=1,N_ITERATIONS do\n",
    "    local indice = torch.random(1,x:size(1))-- picking up a sentence in the training set\n",
    "    local x_i, y_i = x[indice], y[indice]\n",
    "    local m_i = get_facts_memory(indice,f,NUM_MEM)\n",
    "    \n",
    "    -- Going Through the Network \n",
    "    local xrepr = rep:forward(x_i)\n",
    "    local yrepr = rep:forward(y_i)\n",
    "    local a = mem_mod:forward(xrepr) -- a is the table of memories\n",
    "\n",
    "    --\n",
    "    local j = torch.random(1,NUM_MEM) -- picking up a memory\n",
    "    local o_label = o_mod:forward{xrepr, a[m_i[1]]}\n",
    "    if m_i[1] == j then\n",
    "        -- resample if the sampling return the same memory as the supporting one\n",
    "    else \n",
    "        print(a[m_i[1]])\n",
    "        print(a[j])\n",
    "        local o_score = o_mod:forward{xrepr,a[j]}\n",
    "        print(o_label)\n",
    "        print(o_score)\n",
    "        local resized_pred = nn.JoinTable(1):forward{o_label, o_score}\n",
    "        local err = criterion:forward(resized_pred,1)\n",
    "        local gradCriterion = criterion:backward(resized_pred, 1)\n",
    "        print(\"gradCriterion\")\n",
    "        local crit_false = nn.Reshape(1,1,false):forward(gradCriterion[2])\n",
    "        local crit_true = nn.Reshape(1,1,false):forward(gradCriterion[1])\n",
    "        o_mod:zeroGradParameters()\n",
    "        o_mod:backward({xrepr,a[j]},crit_false)\n",
    "        o_mod:backward({xrepr,m_i[1]},crit_true)\n",
    "    end\n",
    "end\n",
    "\n",
    "print(\"Answer \")\n",
    "\n",
    "-- local score_2 = r_mod:forward{xrepr,yrepr}\n",
    "-- print(score_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T23:20:52",
     "start_time": "2017-09-18T21:20:49.206Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T22:46:05",
     "start_time": "2017-09-18T20:46:05.501Z"
    }
   },
   "source": [
    "## Debugging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in pairs(o_mod.forwardnodes) do \n",
    "    if  v.data.annotations.name == \"inference_product\" then -- v.data.annotations.name == \"inference_proj_1\" or v.data.annotations.name == \"inference_proj_2\" or\n",
    "        print(v.data.module.gradInput[2]:fill(torch.random))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T23:45:09",
     "start_time": "2017-09-18T21:45:09.287Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2\t\n"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_facts_memory(10,f,10)[1])\n",
    "--print(f[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T17:12:10",
     "start_time": "2017-09-18T15:12:10.105Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T16:42:19",
     "start_time": "2017-09-18T14:42:19.639Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T15:43:06",
     "start_time": "2017-09-18T13:43:06.912Z"
    },
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.3324330497092e-311\t\n"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local ii = \n",
    "\n",
    "print(ii[2][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T14:10:09",
     "start_time": "2017-09-18T12:10:09.044Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:47:42",
     "start_time": "2017-09-18T10:47:42.288Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T12:50:39",
     "start_time": "2017-09-18T10:50:39.948Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T13:45:28",
     "start_time": "2017-09-18T11:45:28.739Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\t\n",
       "stereo\t\n",
       "2\t\n",
       "in\t\n",
       "3\t\n",
       "the\t\n",
       "4\t\n",
       "landing.\t\n",
       "5\t\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "caden\t\n",
       "6\t\n",
       "joined\t\n",
       "7\t\n",
       "carmen\t\n"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_supporting_facts(indice, fact_tensor,entry_table)\n",
    "    for i=1,fact_tensor:size(2) do \n",
    "        local temp = fact_tensor[indice][i]\n",
    "        if temp ~= 0 then\n",
    "            print(i)\n",
    "            print(index[entry_table[indice][temp]])\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "get_supporting_facts(10,f,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T13:44:30",
     "start_time": "2017-09-18T11:44:30.140Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function get_supporting_memories(indice,facts,num_mem)\n",
    "    \n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T13:49:18",
     "start_time": "2017-09-18T11:49:18.491Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58\t\n"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x:size(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-18T13:49:56",
     "start_time": "2017-09-18T11:49:56.281Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "[string \"local f = function() return math.floor(longue...\"]:1: attempt to perform arithmetic on global 'longuest_sentence_size' (a nil value)\nstack traceback:\n\t[string \"local f = function() return math.floor(longue...\"]:1: in function 'f'\n\t[string \"local f = function() return math.floor(longue...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:210: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105cbaa10",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "[string \"local f = function() return math.floor(longue...\"]:1: attempt to perform arithmetic on global 'longuest_sentence_size' (a nil value)\nstack traceback:\n\t[string \"local f = function() return math.floor(longue...\"]:1: in function 'f'\n\t[string \"local f = function() return math.floor(longue...\"]:1: in main chunk\n\t[C]: in function 'xpcall'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:210: in function </Users/david/torch/install/share/lua/5.1/itorch/main.lua:174>\n\t/Users/david/torch/install/share/lua/5.1/lzmq/poller.lua:80: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:307: in function 'poll'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:325: in function 'sleep_ex'\n\t/Users/david/torch/install/share/lua/5.1/lzmq/impl/loop.lua:370: in function 'start'\n\t/Users/david/torch/install/share/lua/5.1/itorch/main.lua:389: in main chunk\n\t[C]: in function 'require'\n\t(command line):1: in main chunk\n\t[C]: at 0x0105cbaa10"
     ]
    }
   ],
   "source": [
    "math.floor(longuest_sentence_size/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T14:14:40",
     "start_time": "2017-09-15T12:14:40.059Z"
    }
   },
   "source": [
    "## Implementation of the Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T13:53:58",
     "start_time": "2017-09-15T11:53:58.745Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Columns 1 to 26\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0\n",
       " 0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  1  0  0  0  0  0 "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 27 to 52\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       " 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "Columns 53 to 58\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       " 0  0  0  0  0  0\n",
       "[torch.DoubleTensor of size 58x58]\n",
       "\n"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function gradUpdate(mlp, x, y, criterion, learningRate)\n",
    "   local pred = mlp:forward(x)\n",
    "   local err = criterion:forward(pred, y)\n",
    "   local gradCriterion = criterion:backward(pred, y)\n",
    "   mlp:zeroGradParameters()\n",
    "   mlp:backward(x, gradCriterion)\n",
    "   mlp:updateParameters(learningRate)\n",
    "end\n",
    "\n",
    "\n",
    "local xrepr = o:forward(x[1])\n",
    "gradUpdate(mlpa, {{x, y}, {x, z}}, 1, crit, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T13:41:44",
     "start_time": "2017-09-15T11:41:44.425Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T13:40:28",
     "start_time": "2017-09-15T11:40:28.632Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T12:57:11",
     "start_time": "2017-09-15T10:57:11.214Z"
    }
   },
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-09-15T12:58:07",
     "start_time": "2017-09-15T10:58:07.763Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
