{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:48:10",
     "start_time": "2017-06-19T10:48:10.943Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'nngraph';\n",
    "require 'math';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:48:10",
     "start_time": "2017-06-19T10:48:10.969Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataLoader = {}\n",
    "function DataLoader.split(input_file, sep,debug)\n",
    "    --[[\n",
    "        This method seperate the training samples from the label they have been given\n",
    "    ]]\n",
    "    sep = sep or '|'\n",
    "    debug = debug or 0\n",
    "    local x = {}\n",
    "    local y = {}\n",
    "    local w \n",
    "    f = assert(io.open(input_file,\"r\"))\n",
    "    repeat \n",
    "    rawdata= f:read()\n",
    "    if rawdata then \n",
    "        w = rawdata:split(\"|\") \n",
    "        x[#x+1] = w[1]\n",
    "        y[#y+1] = w[2]\n",
    "    end\n",
    "    until not rawdata\n",
    "    return x,y\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:48:10",
     "start_time": "2017-06-19T10:48:10.971Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "out_vocab_file = \"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\"\n",
    "out_tensor_file = \"/Users/david/Documents/MemoryNetwork/output_lua/data.t7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:48:10",
     "start_time": "2017-06-19T10:48:10.974Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "function DataLoader.create_vocabulary(sample_tab,label_tab)\n",
    "    local rawdata\n",
    "    local max_sent_len = 0\n",
    "    local sent_count = 0\n",
    "    local unordered = {}\n",
    "    for i=1,#sample_tab do \n",
    "        -- Writing on Sample File\n",
    "        rawdata = sample_tab[i]\n",
    "\t\tfor k,word in pairs(rawdata:split(\" \")) do \n",
    "\t\t\tword=word:lower()\n",
    "\t\t\tif not unordered[word] then unordered[word] = true end\n",
    "\t\tend\n",
    "\t\tsent_len = #rawdata:split(\" \")\n",
    "\t\tif sent_len > max_sent_len then max_sent_len=sent_len end\n",
    "        -- Writing on Label File\n",
    "        rawdata = label_tab[i]\n",
    "\t\tfor k,word in pairs(rawdata:split(\" \")) do \n",
    "\t\t\tword=word:lower()\n",
    "\t\t\tif not unordered[word] then unordered[word] = true end\n",
    "\t\tend\n",
    "\t\tsent_len = #rawdata:split(\" \")\n",
    "\t\tif sent_len > max_sent_len then max_sent_len=sent_len end\n",
    "\t\tsent_count = sent_count + 1        \n",
    "    end\n",
    "\t-- sort into a table (i.e. keys become 1..N)\n",
    "\tlocal ordered = {}\n",
    "\tfor word in pairs(unordered) do ordered[#ordered + 1] = word end\n",
    "\ttable.sort(ordered)\n",
    "\t-- invert `ordered` to create the char->int mapping\n",
    "\tlocal vocab_mapping = {}\n",
    "\tfor i, word in ipairs(ordered) do\n",
    "\t\tvocab_mapping[word] = i\n",
    "\tend\n",
    "\tprint('saving ' .. out_vocab_file)\n",
    "    torch.save(out_vocab_file, vocab_mapping)\n",
    "    return {sent_count,vocab_mapping,max_sent_len}\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:48:10",
     "start_time": "2017-06-19T10:48:10.976Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "function DataLoader.create_tensor(sent_count,vocab_mapping,max_sent_len,input_tab,tensor_file)\n",
    "\tprint('putting data into tensor...')\n",
    "\tlocal data = torch.ByteTensor(sent_count,max_sent_len):zero()\n",
    "\tlocal currline = 1\n",
    "    local rawdata\n",
    "    for i=1,#input_tab do \n",
    "        rawdata = input_tab[i]:lower()\n",
    "\t\tfor k,word in pairs(rawdata:split(\" \")) do \n",
    "\t\t\tdata[{currline,k}] = vocab_mapping[word:lower()]\n",
    "\t\tend\n",
    "\t\tcurrline = currline + 1\n",
    "    end\n",
    "\t-- save output preprocessed files\n",
    "    print(tensor_file)\n",
    "    torch.save(tensor_file, data)\n",
    "end\n",
    "\n",
    "\n",
    "function DataLoader.text_to_tensor(data_dir, out_vocab_file, out_tensor_file)\n",
    "    local timer = torch.Timer()\n",
    "    local a,b = DataLoader.split(data_dir)\n",
    "    local aa = DataLoader.create_vocabulary(a,b)\n",
    "    \n",
    "    local sent_count = aa[1]\n",
    "    local vocab_mapping = aa[2]\n",
    "    local max_sent_len = aa[3]\n",
    "    local aaa = DataLoader.create_tensor(sent_count,vocab_mapping,max_sent_len,a,out_sample_tensor_file)\n",
    "    local bbb = DataLoader.create_tensor(sent_count,vocab_mapping,max_sent_len,b,out_label_tensor_file)\n",
    "    return aaa,bbb\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing the Loading Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:58:56",
     "start_time": "2017-06-19T10:58:56.347Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- aa,bb = DataLoader.text_to_tensor(input_file,out_vocab_file,out_tensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:58:56",
     "start_time": "2017-06-19T10:58:56.949Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_tensor = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/sample.t7\")\n",
    "label_tensor = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/label.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:58:57",
     "start_time": "2017-06-19T10:58:57.377Z"
    },
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_tensor:size()\n",
    "label_tensor:size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing implemented component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:51",
     "start_time": "2017-06-19T11:44:51.792Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl = require 'utils.data_loader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:52",
     "start_time": "2017-06-19T11:44:51.983Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "saving /Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "putting sample tensor into /Users/david/Documents/MemoryNetwork/output_lua/sample.t7...\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "saving /Users/david/Documents/MemoryNetwork/output_lua/sample.t7\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "putting sample tensor into /Users/david/Documents/MemoryNetwork/output_lua/label.t7...\t\n",
       "saving /Users/david/Documents/MemoryNetwork/output_lua/label.t7\t\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "\n"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dl.text_to_tensor(input_file,out_vocab_file,out_tensor_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:53",
     "start_time": "2017-06-19T11:44:53.030Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/sample.t7\")\n",
    "y = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/label.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:58:05",
     "start_time": "2017-06-19T10:58:05.360Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:53",
     "start_time": "2017-06-19T11:44:53.856Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "require 'nn'\n",
    "require 'models.i_component'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:54",
     "start_time": "2017-06-19T11:44:54.259Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/sample.t7\")\n",
    "y = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/label.t7\")\n",
    "voc = torch.load(\"/Users/david/Documents/MemoryNetwork/output_lua/vocab.t7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:46:34",
     "start_time": "2017-06-19T11:46:34.587Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- We need a method to count the number of items in vocs because the implemented version stops at the first nil value\n",
    "function count_table_elements(t)\n",
    "    local count = 0\n",
    "    for _ in pairs(t) do \n",
    "        count = count+1\n",
    "    end \n",
    "    return count\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:46:34",
     "start_time": "2017-06-19T11:46:34.746Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc_size = count_table_elements(voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:55",
     "start_time": "2017-06-19T11:44:55.563Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = IComponent(voc_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:44:56",
     "start_time": "2017-06-19T11:44:56.811Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = i:forward(x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T14:21:02",
     "start_time": "2017-06-19T12:21:02.049Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = torch.Tensor(5):apply(function(x)\n",
    "    i = 0\n",
    "    i = i + 1\n",
    "    return i\n",
    "end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T14:21:02",
     "start_time": "2017-06-19T12:21:02.422Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = torch.Tensor(x:)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing around with data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T11:52:23",
     "start_time": "2017-06-19T09:52:23.587Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "require 'nn';\n",
    "require 'nngraph';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T11:52:23",
     "start_time": "2017-06-19T09:52:23.589Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "e = torch.Tensor(20):normal(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T11:52:23",
     "start_time": "2017-06-19T09:52:23.591Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = {}\n",
    "table.insert(input,nn.Identity()())\n",
    "lin = nn.Linear(20,100)(input[1])\n",
    "r = nn.Reshape(4,25)(lin)\n",
    "s = nn.SplitTable(1)(r)\n",
    "output = {}\n",
    "table.insert(output,s)-- placeholder)\n",
    "mod = nn.gModule(input,output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T11:52:23",
     "start_time": "2017-06-19T09:52:23.595Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = mod:forward(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T11:52:23",
     "start_time": "2017-06-19T09:52:23.599Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bm = require 'models.base_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T12:53:09",
     "start_time": "2017-06-19T10:53:09.938Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dl = require 'utils.data_loader'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-19T13:52:17",
     "start_time": "2017-06-19T11:52:17.827Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- dl.text_to_tensor(input_file,out_vocab_file,out_tensor_file)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "5.1"
  },
  "latex_envs": {
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 0
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
